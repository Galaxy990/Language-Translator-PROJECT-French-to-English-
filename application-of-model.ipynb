{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Importing required Dependencies**","metadata":{"id":"-JIkRGU6GTrj"}},{"cell_type":"code","source":"from numpy import argmax\nfrom pickle import load\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import model_from_json","metadata":{"id":"F1NLrlQkMHhH","execution":{"iopub.status.busy":"2022-09-07T10:23:24.000926Z","iopub.execute_input":"2022-09-07T10:23:24.001612Z","iopub.status.idle":"2022-09-07T10:23:24.008291Z","shell.execute_reply.started":"2022-09-07T10:23:24.001569Z","shell.execute_reply":"2022-09-07T10:23:24.006846Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**Loading the Cleaned and Preprocessed Text data from .pkl File**","metadata":{"id":"Gq5SVqTtcQtS"}},{"cell_type":"code","source":"dataset = load(open('../input/french-to-english/english-french-both.pkl', 'rb'))","metadata":{"id":"h-_XKg-UMojw","execution":{"iopub.status.busy":"2022-09-07T10:23:36.964193Z","iopub.execute_input":"2022-09-07T10:23:36.964619Z","iopub.status.idle":"2022-09-07T10:23:37.853712Z","shell.execute_reply.started":"2022-09-07T10:23:36.964583Z","shell.execute_reply":"2022-09-07T10:23:37.852728Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"**Creating a Tokenizer for the Sentences and finding the Phrase with Maximum Length**","metadata":{"id":"Avp8Q0-xdaUj"}},{"cell_type":"code","source":"def create_tokenizer(lines):\n\ttokenizer = Tokenizer()\n\ttokenizer.fit_on_texts(lines)\n\treturn tokenizer\n\ndef max_length(lines):\n\treturn max(len(line.split()) for line in lines)","metadata":{"id":"wLD8OFAIPJUf","execution":{"iopub.status.busy":"2022-09-07T10:23:40.631571Z","iopub.execute_input":"2022-09-07T10:23:40.632376Z","iopub.status.idle":"2022-09-07T10:23:40.637718Z","shell.execute_reply.started":"2022-09-07T10:23:40.632334Z","shell.execute_reply":"2022-09-07T10:23:40.636781Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"**Determining the Size of English & French Vocabulary and their respective Phrases with Maximum Length**","metadata":{"id":"cKvmKQxWeRPQ"}},{"cell_type":"code","source":"# preparing the english tokenizer\n\neng_tokenizer = create_tokenizer(dataset[:, 0])\neng_vocab_size = len(eng_tokenizer.word_index) + 1\neng_length = max_length(dataset[:, 0])\n\nprint('English Vocabulary Size: %d' % eng_vocab_size)\nprint('Size Of Maximum Length Phrase in English Vocabulary: %d' % (eng_length))\n\n# preparing the french tokenizer\n\nfra_tokenizer = create_tokenizer(dataset[:, 1])\nfra_vocab_size = len(fra_tokenizer.word_index) + 1\nfra_length = max_length(dataset[:, 1])\nprint('French Vocabulary Size: %d' % fra_vocab_size)\nprint('Size Of Maximum Length Phrase in French Vocabulary: %d' % (fra_length))","metadata":{"id":"lDijv11iQ6CX","outputId":"f33fe371-70a9-411b-aedd-d63f8e3fbe74","execution":{"iopub.status.busy":"2022-09-07T10:23:43.692410Z","iopub.execute_input":"2022-09-07T10:23:43.693241Z","iopub.status.idle":"2022-09-07T10:23:44.593972Z","shell.execute_reply.started":"2022-09-07T10:23:43.693197Z","shell.execute_reply":"2022-09-07T10:23:44.592793Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**Encoding Of the Sentences**","metadata":{"id":"X3k5O2spejJH"}},{"cell_type":"code","source":"# Input and Output sequence must be encoded to integers and padded to the maximum phrase length\ndef encode_sequences(tokenizer, length, lines):\n\t# integer encode sequences\n\tx = tokenizer.texts_to_sequences(lines)\n\t# pad sequences with 0 values\n\tx = pad_sequences(x, maxlen=length, padding='post')\n\treturn x","metadata":{"id":"8WECbBTNRG5W","execution":{"iopub.status.busy":"2022-09-07T10:26:38.402950Z","iopub.execute_input":"2022-09-07T10:26:38.403927Z","iopub.status.idle":"2022-09-07T10:26:38.410272Z","shell.execute_reply.started":"2022-09-07T10:26:38.403873Z","shell.execute_reply":"2022-09-07T10:26:38.408970Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**Loading and Compiling the Created Model**","metadata":{"id":"HexQi4N7iLln"}},{"cell_type":"code","source":"json_file = open('../input/french-to-english/model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nmodel = model_from_json(loaded_model_json)\n# loading the computed weights into the New Model\nmodel.load_weights(\"../input/french-to-english/model.h5\")\nmodel.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc'])","metadata":{"id":"wOrjJUy8SECu","execution":{"iopub.status.busy":"2022-09-07T10:26:41.527025Z","iopub.execute_input":"2022-09-07T10:26:41.527504Z","iopub.status.idle":"2022-09-07T10:26:44.210250Z","shell.execute_reply.started":"2022-09-07T10:26:41.527464Z","shell.execute_reply":"2022-09-07T10:26:44.209021Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"**Evaluating the Loaded Model and Determining the English Translation against User Input**","metadata":{"id":"PamgrtO1tc81"}},{"cell_type":"code","source":"# mapping integer to a word\ndef word_for_id(integer, tokenizer):\n\tfor word, index in tokenizer.word_index.items():\n\t\tif index == integer:\n\t\t\treturn word\n        \n\treturn None\n\n\n# generating target given source sequence\ndef predict_sequence(model, tokenizer, source):\n\tprediction = model.predict(source, verbose=0)[0]\n\tintegers = [argmax(vector) for vector in prediction]\n\ttarget = list()\n    \n\tfor i in integers:\n\t\tword = word_for_id(i, tokenizer)\n\t\tif word is None:\n\t\t\tbreak\n            \n\t\ttarget.append(word)\n        \n\treturn ' '.join(target)","metadata":{"id":"vjz4ERSYT1Df","execution":{"iopub.status.busy":"2022-09-07T10:26:47.889375Z","iopub.execute_input":"2022-09-07T10:26:47.889788Z","iopub.status.idle":"2022-09-07T10:26:47.900382Z","shell.execute_reply.started":"2022-09-07T10:26:47.889754Z","shell.execute_reply":"2022-09-07T10:26:47.898823Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**Performing Predictions on User Input**","metadata":{}},{"cell_type":"code","source":"def frnch_eng(text):\n    sentc = encode_sequences(fra_tokenizer, fra_length, [text])\n    trans = predict_sequence(model, eng_tokenizer, sentc)\n    return trans","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:26:57.567214Z","iopub.execute_input":"2022-09-07T10:26:57.567660Z","iopub.status.idle":"2022-09-07T10:26:57.574137Z","shell.execute_reply.started":"2022-09-07T10:26:57.567623Z","shell.execute_reply":"2022-09-07T10:26:57.572772Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"frnch_eng(\"vous courez tres rapidement\")","metadata":{"execution":{"iopub.status.busy":"2022-09-07T10:31:00.677235Z","iopub.execute_input":"2022-09-07T10:31:00.677656Z","iopub.status.idle":"2022-09-07T10:31:00.753176Z","shell.execute_reply.started":"2022-09-07T10:31:00.677621Z","shell.execute_reply":"2022-09-07T10:31:00.751914Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}